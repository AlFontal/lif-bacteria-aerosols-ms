[
  {
    "objectID": "bacteria_ms.html",
    "href": "bacteria_ms.html",
    "title": "Bacterial Classifier",
    "section": "",
    "text": "In this notebook, we will explore the bacterial-enriched bioaerosols aerosolized with the PALAS AGK 2000, which we then passed through the Rapid-E device with the changed UV laser. We will be loading only the very last 10 minutes of data from the deviced during the times of sampling of each of the 5 bacterial species + the control sample (ringer solution).\nWe will first run an exploratory analysis of the data and then we will train some random forest classifiers to attempt to (1) distinguish between control and bacterial samples, and (2) distinguish between the 5 bacterial species.\nAll the figures and tables in the manuscript are generated in this notebook, so you can reproduce them by running the code below."
  },
  {
    "objectID": "bacteria_ms.html#introduction",
    "href": "bacteria_ms.html#introduction",
    "title": "Bacterial Classifier",
    "section": "",
    "text": "In this notebook, we will explore the bacterial-enriched bioaerosols aerosolized with the PALAS AGK 2000, which we then passed through the Rapid-E device with the changed UV laser. We will be loading only the very last 10 minutes of data from the deviced during the times of sampling of each of the 5 bacterial species + the control sample (ringer solution).\nWe will first run an exploratory analysis of the data and then we will train some random forest classifiers to attempt to (1) distinguish between control and bacterial samples, and (2) distinguish between the 5 bacterial species.\nAll the figures and tables in the manuscript are generated in this notebook, so you can reproduce them by running the code below."
  },
  {
    "objectID": "bacteria_ms.html#preamble",
    "href": "bacteria_ms.html#preamble",
    "title": "Bacterial Classifier",
    "section": "Preamble",
    "text": "Preamble\n\nImports\n\nimport os\nimport bz2\nimport pickle\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotnine as p9\nimport matplotlib.pyplot as plt\n\nfrom glob import glob\nfrom tqdm.auto import tqdm\nfrom functools import partial\nfrom collections import defaultdict\nfrom mizani.breaks import date_breaks\nfrom mizani.formatters import date_format, percent_format\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nfrom aerosolpy.conversion import Conversion\nfrom aerosolpy.particles import AerosolParticlesData, ParticleData\nfrom aerosolpy.particles import (CORRECTED_SPECTRAL_WAVELENGTHS,\n                                 WAVELENGTH_LIFETIME_RANGES,\n                                 SCATTERING_ANGLES)\n\nfrom matplotlib_inline.backend_inline import set_matplotlib_formats\n\n\n\nPre-sets\n\n# Matplotlib settings\nplt.rcParams['font.family'] = 'Georgia'\nplt.rcParams['svg.fonttype'] = 'none'\nset_matplotlib_formats('retina')\nplt.rcParams['figure.dpi'] = 300\n# Plotnine settings (for figures)\n\np9.options.set_option('base_family', 'Georgia')\n\np9.theme_set(\n    p9.theme_bw()\n    + p9.theme(panel_grid=p9.element_blank(),\n               legend_background=p9.element_blank(),\n               panel_grid_major=p9.element_line(size=.5, linetype='dashed',\n                                                alpha=.15, color='black'),\n               dpi=300\n    )\n)\n\n&lt;plotnine.themes.theme_bw.theme_bw at 0x151629e90&gt;\n\n\nJust to aid in the readability of the figures:\n\nbacterial_names = {'bacillus_endophyticus': 'B. endophyticus',\n                   'micrococcus_luteus': 'M. luteus',\n                   'staphylococcus_huminis': 'S. huminis',\n                   'bacillus_cereus': 'B. cereus',\n                   'kocuria_salsicia': 'K. salsicia',\n                   'controls': '*Control'}"
  },
  {
    "objectID": "bacteria_ms.html#data-processing",
    "href": "bacteria_ms.html#data-processing",
    "title": "Bacterial Classifier",
    "section": "Data Processing",
    "text": "Data Processing\n\nRapid-E File Conversion\nWe start by converting the raw files from Rapid-E into a readable JSON through the conversion module. The process generates a json file for each of the minute-long files, which we can then read and load into the AerosolParticlesData class that we have defined in the aerosolpy module.\nGiven that this is a lengthy process, we will store the 10-minute-long AerosolParticlesData objects in a pickle file so that we can load them later without having to repeat the conversion process.\n\nfor folder in glob('../data/Bacterial Samples/*'):\n    if not os.path.exists(f'{folder}/particles.pickle.bz2'):\n        print(f'Processing {folder}')\n        # Convert the files in the folder\n        sample_group = folder.split('/')[-1]\n        for filename in tqdm(glob(f'{folder}/*.zip'), leave=False, desc='File Conversion'):\n            converter = Conversion(filename=filename, mode='user', keep_threshold=True)\n            converter.save_overall()\n        particles = AerosolParticlesData.from_folder(folder)\n        with bz2.BZ2File(f'{folder}/particles.pickle.bz2', 'w') as fh:\n            pickle.dump(particles, fh)\n\nWe now load each of the 10-minute-long AerosolParticlesData objects from the pickle file and store them in a Python dictionary which will ease the access to the data during the analysis.\nEach of the objects contains information for around 48,000 particles:\n\nparticles_dict = {}\nfor bacteria in os.listdir('../data/Bacterial Samples/'):\n        if not bacteria.startswith('.'):\n            folder = f'../data/Bacterial Samples/{bacteria}/'\n            with bz2.BZ2File(f'{folder}/particles.pickle.bz2', 'r') as fh:\n                particles = pickle.load(fh)\n            particles_dict[bacteria] = particles"
  },
  {
    "objectID": "bacteria_ms.html#analysis",
    "href": "bacteria_ms.html#analysis",
    "title": "Bacterial Classifier",
    "section": "Analysis",
    "text": "Analysis\n\nGenerating example plots for Figure 1\nFor figure 1, we generate some example plots of the fluorescence spectra, lifetime and scattering image for a particle. These were made by selecting the highest intensity particle from S. huminis group and plotting each of the three features:\n\nselected_index = (particles_dict['S. huminis']\n .summary_df\n .sort_values('intensity', ascending=False)\n .index[0]\n)\n\nFluorescence spectra:\n\n(particles_dict['S. huminis'][selected_index]\n .spectral_data\n .assign(time=lambda dd: dd.time.astype(float))\n .pipe(lambda dd: \n       p9.ggplot(dd)\n       + p9.aes(x='wavelength', y='intensity', color='time')\n       + p9.geom_line(p9.aes(group='time'))\n       + p9.labs(x='Wavelength (nm)', y='Intensity (a.u.)', color='Time (µs)')\n       + p9.theme(\n           figure_size=(3, 2),\n           legend_position=(1, 1),\n           legend_key_size=7,\n           legend_text=p9.element_text(size=6),\n           legend_title=p9.element_text(size=8, ha='center'),\n)))\n\n\n\n\n\n\n\n\nFluorescence lifetime:\n\n(particles_dict['S. huminis'][selected_index]\n .lifetime\n .replace({'350-400 nm': '300-340 nm'})\n .pipe(lambda dd: p9.ggplot(dd)\n        + p9.aes(x='time', y='intensity', color='wavelength_range')\n        + p9.geom_line(size=.7)\n        + p9.guides(color=p9.guide_legend(ncol=1))\n        + p9.scale_x_continuous(expand=(0.01, 0.01))\n        + p9.scale_color_manual(values=[\n            '#ab2422','#D3894C', '#435B97', '#32a86d'])\n        + p9.labs(x='Time (ns)', y='Intensity (a.u.)', color='')\n        + p9.theme(figure_size=(3, 2),\n                   legend_text=p9.element_text(size=7),\n                   legend_key_size=9,\n                   legend_position=(.95, 1.15))\n ))\n\n\n\n\n\n\n\n\nScattering image:\n\n(particles_dict['S. huminis'][selected_index]\n .scattering\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes('time', 'angle', fill='intensity / 10000')\n       + p9.geom_tile()\n       + p9.scale_fill_cmap('inferno')\n       + p9.scale_x_continuous(expand=(0, 0))\n       + p9.scale_y_continuous(expand=(0, 0))\n       + p9.theme(figure_size=(3, 2), legend_key_size=10,\n                  legend_title=p9.element_text(size=8),\n                  legend_text=p9.element_text(size=6))\n       + p9.labs(x='Time (µs)', y='Angle (°)', fill='Intensity\\n(a.u.)')\n       )\n)\n\n\n\n\n\n\n\n\n\n\nSupplementary Figure 2: Size and fluorescence intensity distributions\nAs a propierty of the AerosolParticlesData class, we provide easy access to a summary_df that contains the timestamp, estimated size, max fluorescence intensity and time of max fluorescence intensity for each of the particles as a pandas DataFrame. We collect this information for each of the classes so that we can plot the different distributions of these properties, along with some extra stats:\n\nsummaries = []\nfor sample_type, ps in particles_dict.items():\n    summaries.append(ps.summary_df.assign(group=sample_type))\nsummaries = pd.concat(summaries)\n\n\nintensity_stats = (summaries\n .groupby('group')\n .agg(mean=('intensity', 'mean'),\n      median=('intensity', 'median'),\n      q95=('intensity', lambda x: np.percentile(x, 95)),\n      q99=('intensity', lambda x: np.percentile(x, 99)))\n      .reset_index()\n      .assign(label=lambda dd: 'Median = ' + dd['median'].round(2).astype(str) + \n              '\\n\\nQ95 = ' + dd['q95'].round(2).astype(str) + \n              '\\n\\nQ99 = ' + dd['q99'].round(2).astype(str))\n      .sort_values('median', ascending=False)\n      .assign(group=lambda dd: \n              pd.Categorical(dd['group'], categories=dd['group'].values, ordered=True))\n)\n\nsize_stats = (summaries\n      .groupby('group')\n      .agg(mean=('size', 'mean'),\n           median=('size', 'median'),\n           q95=('size', lambda x: np.percentile(x, 95)),\n           q99=('size', lambda x: np.percentile(x, 99)))\n      .reset_index()\n      .assign(label=lambda dd: 'Median = ' + dd['median'].round(2).astype(str) + \n              '\\n\\nQ95 = ' + dd['q95'].round(2).astype(str) + \n              '\\n\\nQ99 = ' + dd['q99'].round(2).astype(str))\n      .sort_values('median', ascending=False)\n      .assign(group=lambda dd: \n              pd.Categorical(dd['group'], categories=dd['group'].values, ordered=True))\n      )\n\n\nf = (summaries\n .assign(group=lambda dd: pd.Categorical(dd['group'], categories=size_stats['group'].values, ordered=True))\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes('size') \n       + p9.geom_histogram(bins=100) \n       + p9.facet_wrap('group', ncol=1, scales='free_y')\n       + p9.scale_x_continuous(limits=(None, 9))\n       + p9.geom_vline(p9.aes(xintercept='median'), color='red', linetype='dashed',\n                       data=size_stats)\n       + p9.geom_vline(p9.aes(xintercept='q95'), color='blue', linetype='dashed',\n                          data=size_stats)\n       + p9.geom_vline(p9.aes(xintercept='q99'), color='blue', linetype='dotted',\n                       data=size_stats)\n       + p9.geom_text(p9.aes(x=8, y=500, label='label'), va='bottom',\n                      size=7, color='black', ha='left', data=size_stats)\n       + p9.labs(x='Estimated diameter [µm]', y='Particles count')\n       + p9.ggtitle(''))\n       + p9.theme(figure_size=(5, 6))\n)\nf.save('../output/figures/size_distribution.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\nf = (summaries\n  .assign(group=lambda dd: \n          pd.Categorical(dd['group'], categories=intensity_stats['group'].values, ordered=True))\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes('intensity') \n       + p9.geom_histogram(bins=100) \n       + p9.facet_wrap('group', ncol=1, scales='free_y')\n       + p9.scale_x_continuous(limits=(None, 3800), expand=(0, 0))\n       + p9.geom_vline(p9.aes(xintercept='median'), color='red', linetype='dashed',\n                       data=intensity_stats)\n       + p9.geom_vline(p9.aes(xintercept='q95'), color='blue', linetype='dashed',\n                          data=intensity_stats)\n       + p9.geom_vline(p9.aes(xintercept='q99'), color='blue', linetype='dotted',\n                       data=intensity_stats)\n\n       + p9.geom_text(p9.aes(x=3050, y=225, label='label'), va='bottom',\n                      size=7, color='black', ha='left', data=intensity_stats)\n       + p9.labs(x='Fluorescence Intensity [a.u.]', y='Particles count')\n       + p9.ggtitle(''))\n       + p9.theme(figure_size=(5, 6))\n)\nf.save('../output/figures/intensity_distribution_bacteria.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\n\nVisualizing fluorescence spectra (Figure 7)\nGiven that we have over 47000 particles for each sample group, and assuming that a majority of particles won’t either contain the desired bacterial cells or be excited properly by the UV-laser, we will only focus on the fluorescence spectra of those that showed a high fluorescence intensity peak at any point in time and wavelength. We set the arbitrary threshold of 2000 a.u. since it represents, for all groups, a point between the 95th and 99th percentiles of the maximum fluorescence spectra distribution:\n\nfluo_particles_dict = {}\nfor group, particles in particles_dict.items():\n    fluo_particles_dict[group] = particles.filter('intensity &gt; 2000')\n\nFiltering particles with query: intensity &gt; 2000\nFiltering particles with query: intensity &gt; 2000\nFiltering particles with query: intensity &gt; 2000\nFiltering particles with query: intensity &gt; 2000\nFiltering particles with query: intensity &gt; 2000\nFiltering particles with query: intensity &gt; 2000\n\n\nTo visualize the fluorescence spectra, we will aggregate the intensities across all 8 time captures for each of the filtered particles:\n\nspectra_df = []\nfor group, particles in fluo_particles_dict.items():\n    for i, particle in enumerate(particles):\n        spectra_df.append(particle.spectrum_time_matrix\n        .sum(axis=1)\n        .rename('intensity')\n        .reset_index()\n        .assign(relative_intensity=lambda dd: dd['intensity'] / dd['intensity'].max())\n        .assign(group=group)\n        .assign(particle_index=i)\n        .assign(max_intensity=lambda dd: dd['intensity'].max())\n )\nspectra_df = pd.concat(spectra_df)\n\nAnd now, if we simply showcase the 100 individual particles which showed the highest fluorescence intensities for each of the groups, with the intensities scaled to a 0-100% scale on a particle-by-particle basis:\n\nn = 100\nselected_particles = (spectra_df\n .groupby('group')\n .apply(lambda dd: dd\n        [['particle_index', 'max_intensity']]\n        .drop_duplicates()\n        .sort_values('max_intensity', ascending=False)\n        .head(n)\n        .assign(new_index=range(n)),\n        include_groups=False)\n        .reset_index()\n [['group', 'particle_index', 'new_index']]\n)\n\n(spectra_df\n .merge(selected_particles, on=['group', 'particle_index'])\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes(x='wavelength', y='new_index')\n         + p9.geom_tile(p9.aes(fill='relative_intensity'))\n         + p9.scale_x_continuous(expand=(0, 0), breaks=range(330, 630, 50))\n         + p9.scale_y_continuous(expand=(0, 0))\n         + p9.scale_fill_cmap('viridis', labels=percent_format())\n         + p9.facet_wrap('group')\n         + p9.labs(x='Wavelength [nm]', fill='Relative\\nIntensity')\n         + p9.theme(axis_text_y=p9.element_blank(),\n                      axis_title_y=p9.element_blank(),\n                      axis_ticks_major_y=p9.element_blank(),\n                      legend_position='right',\n                      legend_key_size=10,\n                      legend_text=p9.element_text(size=7),\n                      legend_title=p9.element_text(size=9, ha='center', y=45),\n                      axis_title_x=p9.element_text(size=10, va='top'),\n                      axis_text_x=p9.element_text(size=7),\n                      figure_size=(6, 3.5),\n                      plot_margin=.03\n         )\n )\n)\n\n\n\n\n\n\n\n\nWe observe how the 320-340 nm is very commonly the wavelength of peak intensity across particles of all groups, with some individual particles peaking in different values in the 400-450 nm range in all bacteria groups (and not so much in the controls).\nIf we then showcase the median intensities of all the filtered particles for each sample group and wavelength, this common 330 nm peak becomes more clear:\n\n(spectra_df\n .merge(selected_particles, on=['group', 'particle_index'])\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes(x='wavelength', y='relative_intensity')\n       + p9.scale_x_continuous(breaks=range(300, 601, 50))\n       + p9.scale_y_continuous(breaks=[0, .2, .4, .6, .8, 1])\n       + p9.labs(\n           y='Relative Fluorescence Intensity [a.u.]', \n           x='Wavelength [nm]', \n           color='', \n           fill='')\n       + p9.stat_summary(geom='line', size=.7, fun_y=np.median, mapping=p9.aes(color='group'))\n       + p9.guides(linetype=False)\n       + p9.theme(figure_size=(4, 2.5),\n                  axis_title_y=p9.element_text(size=9),\n                  axis_text_y=p9.element_text(size=8),\n                  legend_position=(.99, 1.05),\n                  legend_key_size=11,\n                  legend_text=p9.element_text(size=8.5),\n                  \n       )\n    )\n       )\n\n\n\n\n\n\n\n\n\n(spectra_df\n .merge(selected_particles, on=['group', 'particle_index'])\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes(x='wavelength', y='relative_intensity')\n       + p9.scale_x_continuous(breaks=range(300, 601, 50))\n       + p9.scale_y_continuous(breaks=[0, .2, .4, .6, .8, 1])\n       + p9.labs(\n           y='Relative Fluorescence Intensity [a.u.]', \n           x='Wavelength [nm]', \n           color='', \n           fill=''\n           )\n       + p9.facet_wrap('group', ncol=3)\n       + p9.stat_summary(\n           geom='line', \n           size=.7, \n           fun_y=np.median, \n           mapping=p9.aes(color='group')\n           )\n       + p9.stat_summary(\n           fun_ymax=lambda x: x.quantile(.75),\n           fun_ymin=lambda x: x.quantile(.25),\n           geom='ribbon', \n           alpha=.25, \n           mapping=p9.aes(fill='group')\n           )\n       + p9.guides(linetype=False, color=False, fill=False)\n       + p9.theme(figure_size=(5, 3),\n                  axis_title_y=p9.element_text(size=10),\n                  axis_text=p9.element_text(size=7),\n       )\n    )\n       )\n\n\n\n\n\n\n\n\n\n\nFluorescence Lifetimes\n\nlifetimes = []\nfor group, particles in fluo_particles_dict.items():\n    for i, particle in enumerate(particles):\n        lifetimes.append(particle.lifetime\n                         .assign(group=group)\n                         .assign(particle_index=i)\n        )\nlifetimes = pd.concat(lifetimes)\nn = 10\nselected_lifetime_top = (lifetimes\n                         .query('wavelength_range == \"350-400 nm\"')\n .groupby(['group', 'particle_index'], as_index=False)\n .intensity.sum()\n .groupby(['group'], as_index=False)\n [['group', 'particle_index', 'intensity']]\n .apply(lambda dd: dd.sort_values('intensity', ascending=False).head(n).assign(new_index=range(n)))\n [['group', 'particle_index', 'new_index']]\n)\n\nselected_lifetimes = lifetimes.merge(selected_lifetime_top, on=['group', 'particle_index'])\n\n\n(selected_lifetimes\n .pipe(lambda dd: p9.ggplot(dd) + p9.aes('time', 'intensity', color='wavelength_range')\n         + p9.geom_line()\n         + p9.facet_grid('new_index ~ group', scales='free_y')\n         + p9.theme(legend_position='top',\n                    figure_size=(6, 7),\n                    )\n       )\n)\n\n\n\n\n\n\n\n\n\nlifetimes_matrix = (\n    lifetimes.pivot(index=['group', 'particle_index'], columns=['time', 'wavelength_range'], values='intensity')\n\n)\nlifetimes_matrix.columns = [f'{time}_{wavelength_range}' for time, wavelength_range in lifetimes_matrix.columns]\nlifetimes_matrix = lifetimes_matrix.reset_index()\n\n\nn = 100\nselected_lifetime_top100 = (lifetimes\n                         .query('wavelength_range == \"350-400 nm\"')\n .groupby(['group', 'particle_index'], as_index=False)\n .intensity.sum()\n .groupby(['group'], as_index=False)\n [['group', 'particle_index', 'intensity']]\n .apply(lambda dd: dd.sort_values('intensity', ascending=False).head(n).assign(new_index=range(n)))\n [['group', 'particle_index', 'new_index']]\n)\n\n\n\nlifetime_stats = (lifetimes\n .query('particle_index in @selected_lifetime_top100.particle_index')\n .replace({'350-400 nm': '300-340 nm'})\n .groupby(['group', 'time', 'wavelength_range'], as_index=False)\n .agg(\n     median=('intensity', 'median'),\n    q05=('intensity', lambda x: x.quantile(.05)),\n    q25=('intensity', lambda x: x.quantile(.25)),\n    q75=('intensity', lambda x: x.quantile(.75)),\n    q95=('intensity', lambda x: x.quantile(.95)),\n    q99=('intensity', lambda x: x.quantile(.99)),\n )\n)\n\nf = (lifetime_stats\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes(x='time', y='median', color='wavelength_range')\n       + p9.geom_line()\n       + p9.facet_wrap('group', ncol=3)\n       + p9.labs(x='Time [ns]', y='Median Intensity [a.u.]', color='Wavelength Range')\n       + p9.theme(\n           legend_position='top',\n           figure_size=(5, 3.5),\n           legend_title=p9.element_text(size=9),\n           legend_text=p9.element_text(size=8),\n           legend_key_size=11,\n                  )\n )\n)\nf.save('../output/figures/lifetime_stats.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\nf = (lifetime_stats\n .query('wavelength_range == \"300-340 nm\"')\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes(x='time', y='median')\n       + p9.geom_line(p9.aes(color='wavelength_range'))\n       + p9.geom_ribbon(p9.aes(ymin='q25', ymax='q75', fill='wavelength_range'), alpha=.25)\n       + p9.geom_ribbon(p9.aes(ymin='q05', ymax='q95', fill='wavelength_range'), alpha=.15)\n       + p9.facet_wrap('group', ncol=3)\n       + p9.labs(x='Time [ns]', y='Intensity [a.u.]', color='Wavelength Range')\n       + p9.guides(fill=False)\n       + p9.theme(\n           legend_position='top',\n           figure_size=(5, 3.5),\n           legend_title=p9.element_text(size=9),\n           legend_text=p9.element_text(size=8),\n           legend_key_size=11,\n                  )\n )\n)\nf.save('../output/figures/lifetime_stats_300_340.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\n\nScattering Images\n\npd.set_option('future.no_silent_downcasting', True)\n\n\nscatterings = []\nfor group, particles in fluo_particles_dict.items():\n    for i, particle in enumerate(particles):\n        scatterings.append(particle.scattering\n                           .assign(group=group)\n                           .assign(particle_index=i)\n        )\nscatterings = pd.concat(scatterings)\n\n\n(scatterings\n  .merge(selected_particles, on=['group', 'particle_index'])\n .groupby(['group', 'particle_index'], as_index=False)\n .apply(lambda dd: dd.query('time == time.max()'))\n .pipe(lambda dd: p9.ggplot(dd) + p9.aes('group', 'time') \n       + p9.geom_boxplot(p9.aes(fill='group'), alpha=.7, outlier_stroke=0, outlier_alpha=.5)\n       + p9.scale_y_continuous(limits=(0, 100))\n       + p9.scale_x_discrete(limits=dd.group.unique()[::-1])\n       + p9.coord_flip()\n       + p9.guides(fill=False)\n       + p9.labs(x='', y='Total duration of scattering signal [µs]')\n       + p9.theme(figure_size=(4, 3))\n )\n)\n\n\n\n\n\n\n\n\n\n(scatterings\n  .merge(selected_particles, on=['group', 'particle_index'])\n .groupby(['group', 'particle_index'], as_index=False)\n .apply(lambda dd: dd.groupby(['time', 'group'], as_index=False)\n        .intensity.sum()\n        .query('intensity == intensity.max()'))\n .pipe(lambda dd: p9.ggplot(dd) + p9.aes('group', 'time') \n       + p9.geom_boxplot(p9.aes(fill='group'), alpha=.7, outlier_stroke=0, outlier_alpha=.5)\n       + p9.scale_y_continuous(limits=(0, 100))\n       + p9.scale_x_discrete(limits=dd.group.unique()[::-1])\n       + p9.coord_flip()\n       + p9.guides(fill=False)\n       + p9.labs(x='', y='Time of max intensity of scattering signal [µs]')\n       + p9.theme(figure_size=(4, 3),\n                  axis_title_x=p9.element_text(size=10),\n                  axis_text_x=p9.element_text(size=8),\n       )\n )\n)\n\n\n\n\n\n\n\n\n\nscattering_stats = (scatterings\n .groupby(['group', 'particle_index', 'time'], as_index=False)\n .agg(intensity=('intensity', 'sum'))\n .groupby(['group', 'particle_index'], as_index=False)\n .apply(lambda dd: dd.assign(norm_intensity=lambda x: x['intensity'] / x['intensity'].max()))\n .groupby(['group', 'time'], as_index=False)\n .agg(\n     median=('norm_intensity', 'median'),\n     q05=('norm_intensity', lambda x: np.percentile(x, 5)),\n     q95=('norm_intensity', lambda x: np.percentile(x, 95)),\n     q25=('norm_intensity', lambda x: np.percentile(x, 25)),\n     q75=('norm_intensity', lambda x: np.percentile(x, 75))\n )\n)\n\n\ndef compute_percentiles(group, variable='time'):\n    percentiles = np.arange(0, 101, 1)\n    return np.percentile(group[variable], percentiles)\n\nscattering_time_stats = (scatterings\n .groupby(['group', 'particle_index'], as_index=False)\n .agg(time=('time', 'max'))\n .groupby('group')\n .apply(compute_percentiles)\n .apply(pd.Series)\n .reset_index()\n)\n\n\nFigure 3: Light scfattering acquisition statistics\n\n(scattering_time_stats\n .melt('group', var_name='percentile', value_name='time')\n .assign(percentile=lambda dd: dd['percentile'].astype(int))\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes('time', 'percentile', color='group')\n         + p9.geom_line(size=.6)\n         + p9.scale_x_continuous(limits=(0, 140))\n         + p9.scale_y_continuous(expand=(0.01, 0.01))\n         + p9.labs(x='Acquisition time [µs]', y='Percentile of particles', color='')\n         + p9.theme(\n            figure_size=(4, 3),\n            legend_position=(.95, .2),\n            legend_key_size=13,\n            legend_text=p9.element_text(size=10),\n         )\n)\n)\n\n\n\n\n\n\n\n\n\nf = (scattering_time_stats\n .melt('group', var_name='percentile', value_name='time')\n .assign(percentile=lambda dd: dd['percentile'].astype(int))\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes('time', 'percentile', color='group')\n         + p9.geom_line(size=.6)\n         + p9.scale_x_continuous(limits=(0, 120), expand=(0, 0), breaks=range(0, 101, 20))\n         + p9.scale_y_continuous(expand=(0, 0), breaks=range(0, 101, 20))\n         + p9.facet_wrap('group', ncol=3)\n         + p9.guides(color=False)\n         + p9.geom_segment(p9.aes(xend='time'), x=0, y=90, yend=90, color='black',\n                           linetype='dashed',\n                           size=.5, data=dd.query('percentile == 90'))\n         + p9.geom_segment(p9.aes(x='time', xend='time'), y=0, yend=90, color='black',\n                           linetype='dashed',\n                           size=.5, data=dd.query('percentile == 90'))\n         + p9.geom_point(p9.aes(x='time', y=90), size=1.5, stroke=0, color='black',\n                         data=dd.query('percentile == 90'))\n         + p9.geom_label(p9.aes(y=15, label='\"$q_{90}$ = \" + time.round(1).astype(str) + \" µs\"'),\n                          size=7, x=55, ha='left',  \n                         data=dd.query('percentile == 90'), color='black')\n         + p9.geom_segment(p9.aes(xend='time'), x=0, y=80, yend=80, color='black',\n                           linetype='dashed',\n                           size=.5, data=dd.query('percentile == 80'))\n         + p9.geom_segment(p9.aes(x='time', xend='time'), y=0, yend=80, color='black',\n                           linetype='dashed',\n                           size=.5, data=dd.query('percentile == 80'))\n         + p9.geom_point(p9.aes(x='time', y=80), size=1.5, stroke=0, color='black',\n                         data=dd.query('percentile == 80'))\n         + p9.geom_label(p9.aes(label='\"$q_{80}$ = \" + time.round(1).astype(str) + \" µs\"'),\n                          x=55, size=7, ha='left', y=32.5,  \n                         data=dd.query('percentile == 80'), color='black')\n         + p9.labs(x='Light scattering acquisition time [µs]', y='Percentile of particles', color='')\n         + p9.theme(\n            figure_size=(5, 3),\n            legend_position=(.95, .2),\n            legend_key_size=11,\n            axis_text=p9.element_text(size=8),\n         )\n)\n)\n\nf.save('../output/figures/scattering_time_percentiles.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\nf = (scattering_stats\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes('time', 'median')\n       + p9.annotate('vline', xintercept=30, color='black', linetype='dashed')\n       + p9.geom_line(p9.aes(color='group'), size=.7)\n       + p9.scale_x_continuous(limits=(0, 50), expand=(0, 0))\n       + p9.scale_y_continuous(breaks=[0, .2, .4, .6, .8, 1], expand=(0, 0), limits=(0, 1))\n       + p9.labs(x='Time [µs]', y='Normalized intensity [0-1]', color='')\n       + p9.guides(color=p9.guide_legend(ncol=2))\n       + p9.theme(figure_size=(3.5, 2.5),\n                  legend_position=(.05, .1),\n                  legend_key_size=10,\n                  axis_text=p9.element_text(size=8),\n                  axis_title_y=p9.element_text(size=10),\n                  legend_text=p9.element_text(size=8),\n                  legend_title=p9.element_text(size=9),\n       )\n )\n )\nf.save('../output/figures/scattering_time_stats.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\n\nSupplementary Figure 3: Scattering intensity as a function of time of acquisition\n\n(scattering_stats\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes('time', 'median')\n       + p9.geom_line(p9.aes(color='group'), size=.7)\n       + p9.geom_ribbon(p9.aes(ymin='q25', ymax='q75', fill='group'), alpha=.35)\n       + p9.geom_ribbon(p9.aes(ymin='q05', ymax='q95', fill='group'), alpha=.25)\n       + p9.scale_x_continuous(limits=(0, 50))\n       + p9.scale_y_continuous(breaks=[0, .2, .4, .6, .8, 1], expand=(0, 0))\n       + p9.facet_wrap('group')\n       + p9.guides(color=False, fill=False)\n       + p9.labs(x='Time [µs]', y='Normalized intensity [0-1]', color='')\n       + p9.theme(figure_size=(5, 3),\n                  legend_position='top',\n                  legend_key_size=10,\n                  legend_text=p9.element_text(size=8),\n                  legend_title=p9.element_text(size=9),\n       )\n )\n )\n\n\n\n\n\n\n\n\n\n\nSupplementary Figure 1: Scattering image examples\n\n(scatterings\n .merge(selected_particles, on=['group', 'particle_index'])\n .query('new_index &lt; 5')\n.assign(angle=lambda dd: dd.angle.astype(float))\n.assign(time=lambda dd: dd.time.astype(float))\n.assign(particle_label=lambda dd: 'Part. #' + (dd['new_index'] + 1).astype(str))\n .pipe(lambda dd: p9.ggplot(dd) \n       + p9.aes(x='time', y='angle', fill='intensity')\n       + p9.geom_tile()\n       + p9.facet_grid('group~particle_label')\n       + p9.scale_fill_cmap('inferno', labels=lambda x: [int(i / 1e6) for i in x])\n       + p9.scale_x_continuous(expand=(0, 0), limits=(0, 30), breaks=[10, 20, 30])\n       + p9.scale_y_continuous(expand=(0, 0))\n       + p9.labs(x='Time [µs]', y='Angle [°]', fill='Intensity\\n[a.u.]')\n       + p9.theme(figure_size=(6, 6),\n                  panel_background=p9.element_rect(fill='black'),\n                  panel_grid=p9.element_blank(),\n                  strip_text_y=p9.element_text(size=7.5),\n                  legend_key_size=11,\n                  legend_title=p9.element_text(size=8, ha='center'),\n                  legend_text=p9.element_text(size=7),\n                  )\n       )\n )\n\n\n\n\n\n\n\n\n\nscatter_prepared = (scatterings.query('time &lt; 30')\n .pivot(index=['group', 'particle_index', 'angle'], columns='time', values='intensity')\n .fillna(0)\n .reset_index()\n .melt(id_vars=['group', 'particle_index', 'angle'], var_name='time', value_name='intensity')\n .pivot(index=['group', 'particle_index'], columns=['angle', 'time'], values='intensity')\n .apply(lambda x: x / x.max(), axis=1)\n .reset_index()\n)\nscatter_prepared.columns = [f'{round(angle, 1)}_{time}' if time != '' else angle for angle, time in scatter_prepared.columns]\n\n\nscatter_window = 60\nscatter_images = []\nfor group, particles in tqdm(fluo_particles_dict.items(), leave=False):\n    for i, particle in tqdm(enumerate(particles), total=len(particles), leave=False):\n        max_intensity = particle.scattering.intensity.max()\n        total_time = particle.scattering_matrix.shape[0]\n        scatter_images.append(\n                particle\n                .scattering_matrix\n                .reindex(np.arange(total_time // 4 - scatter_window // 4,\n                                   total_time // 4 + scatter_window // 4, .5),\n                         fill_value=0)\n                .reset_index(drop=True)\n                .apply(lambda x: x / max_intensity)\n                .reset_index()\n                .melt('index')\n                .assign(particle=i)\n                .assign(group=group)\n            )\nscatter_images = pd.concat(scatter_images)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nscatter_images_prepared = (scatter_images\n                           .rename(columns={'particle': 'particle_index'})\n                           .pivot(\n                               index=['group', 'particle_index'],\n                               columns=['index', 'angle'],\n                               values='value')\n                           \n)\n\nscatter_images_prepared.columns = [f'{round(angle, 1)}_{time}' if time != '' else\n                                   angle for angle, time in scatter_images_prepared.columns]\n\n\n\nSupplementary Figure 5: Average scattering images\n\nf = (scatter_images\n .rename(columns={'particle': 'particle_index'})\n .merge(selected_particles, on=['group', 'particle_index'])\n .groupby(['group', 'angle', 'index'])\n ['value']\n .mean()\n .reset_index()\n .assign(time=lambda dd: dd['index'] / 2)\n .assign(angle=lambda dd: dd.angle.round(1))\n .pipe(lambda dd: p9.ggplot(dd) \n       + p9.aes('factor(time)', 'factor(angle)', fill='value')\n       + p9.geom_tile()\n       + p9.facet_wrap('group')\n       + p9.scale_fill_continuous('inferno')\n       + p9.scale_y_discrete(expand=(0, 0), breaks=[n for i, n in enumerate(dd['angle'].unique()) if i % 4 == 0])\n       + p9.scale_x_discrete(expand=(0, 0), breaks=[int(n) for n in dd['time'].unique() if n % 5 == 0])\n       + p9.labs(x='Time [µs]', y='Angle [°]', fill='Relative Intensity [a.u.]')\n       + p9.theme(figure_size=(5, 4), legend_position='top', axis_text=p9.element_text(size=8),\n                  legend_key_height=15)\n       )\n)\nf.save('../output/figures/supp_5_scattering_images.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\n\n\n2-D projection via PCA\n\nspectra = pd.concat([p.spectra.assign(group=g)\n                     .reset_index(drop=True)\n                     .reset_index()\n                     .rename(columns={'index': 'particle_index'})\n                     for g, p in fluo_particles_dict.items()])\n\n\na = spectra.copy()\nb = lifetimes_matrix.copy()\nc = scatter_prepared.copy()\nc.set_index(['group', 'particle_index'], inplace=True)\nb.set_index(['group', 'particle_index'], inplace=True)\na.set_index(['group', 'particle_index'], inplace=True)\n\n\npca_dfs = []\nimportances_df = dict()\nfor var_name, df in zip(\n    ['Fluorescence Spectra', 'Fluorescence Lifetimes', 'Light Scattering'],\n    [a, b, c]):\n    df = df.copy()\n    df.columns = range(df.shape[1])\n    scaled_matrix = StandardScaler().fit_transform(df)\n    pca_particles = PCA(n_components=40).fit(scaled_matrix)\n    importances = pca_particles.explained_variance_ratio_\n    importances_df[var_name] = importances\n    pca_dfs.append(pd.DataFrame(pca_particles.transform(scaled_matrix))\n                           .rename(columns={i: f'PC{i + 1}' for i in range(40)})\n                           .iloc[: :2] \n                           .assign(group=df.reset_index().group)\n                           .assign(particle_index=df.reset_index().particle_index)\n                           .assign(var_name=var_name)\n\n                           )\n    \nimportances_map = {k: f'{v[:2].sum():.2%}' for k, v in importances_df.items()}\n\n\nf = (pd.concat(pca_dfs)\n .sort_values('group', ascending=False)\n .assign(var_label=lambda dd: dd['var_name'] + \" (\" + dd['var_name'].map(importances_map) + \")\")\n .pipe(lambda dd: p9.ggplot(dd) \n       + p9.aes('PC1', 'PC2', color='group') \n       + p9.geom_point(alpha=.6, stroke=0, size=1.5)\n       + p9.stat_ellipse(p9.aes(fill='group'), type='norm')\n       + p9.labs(color='', x=f'PC1', y=f'PC2')\n       + p9.facet_wrap('var_label', ncol=3, scales='free')\n       + p9.guides(color=p9.guide_legend(override_aes={'alpha': 1}, ncol=6))\n       + p9.theme(figure_size=(7, 3),\n                  legend_position='top',\n                  legend_text=p9.element_text(size=9),\n                  )\n )\n)\n\nf.save('../output/figures/pca_bacteria.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\nClassification with Random Forest Classifier\n\nPreparing the matrix\n\nfull_matrix = (spectra\n               .merge(lifetimes_matrix, on=['group', 'particle_index'], suffixes=('_spectrum', '_lifetime'))\n               .merge(scatter_prepared, on=['group', 'particle_index'])\n               .set_index(['group', 'particle_index'])\n               )\n\nfull_matrix.columns = range(full_matrix.shape[1])\n\n\n\n\n\nModel training and evaluation\nWe will train several models using all possible combinations of the scattering image, fluorescence spectra and fluorescence lifetime features. We will perform hyperparameter exploration of each of these different models and then evaluate both the binary and multiclass classification performance using class-balanced accuracy, precision, recall and F1-score.\n\nEvaluating model with selected hyperparameters\n\nnp.random.seed(42)\nsections_list = [spectra\n                 .sort_values(['group', 'particle_index'])\n                 .set_index(['group', 'particle_index']),\n    lifetimes_matrix\n    .sort_values(['group', 'particle_index'])\n    .set_index(['group', 'particle_index']),\n    scatter_prepared\n    .sort_values(['group', 'particle_index'])\n    .set_index(['group', 'particle_index'])]\n\nmatrices = [pd.concat([sections_list[0], sections_list[1], sections_list[2]], axis=1),\n            pd.concat([sections_list[0], sections_list[1]], axis=1),\n            pd.concat([sections_list[0], sections_list[2]], axis=1),\n            pd.concat([sections_list[1], sections_list[2]], axis=1),\n            sections_list[0],\n            sections_list[1],\n            sections_list[2]\n            ]\n\nmatrix_names = [\n    'Fluorescence spectra + Lifetimes + Scatter Images',\n    'Fluorescence spectra + Lifetimes',\n    'Fluorescence spectra + Scatter Images',\n    'Lifetimes + Scatter Images',\n    'Fluorescence spectra only',\n    'Lifetimes only',\n    'Scatter Images only'\n]\n\n\ny = sections_list[0].reset_index().group\n\nx_train_indexes, x_test_indexes = train_test_split(\n    range(len(full_matrix)), test_size=.4, random_state=42)\n\nx_test_indexes, x_val_indexes = train_test_split(\n    x_test_indexes, test_size=.5, random_state=42)\n\nmodel_results = defaultdict(list)\nfor matrix, name in tqdm(zip(matrices, matrix_names), total=len(matrices)):\n\n    matrix.columns = range(len(matrix.columns))\n    for depth in tqdm(range(3, 20, 2), leave=False):\n        for n_trees in tqdm(range(50, 300, 25), leave=False):\n            X_train = matrix.iloc[x_train_indexes]\n            X_test = matrix.iloc[x_test_indexes]\n            X_val = matrix.iloc[x_val_indexes]\n            y_train = y.iloc[x_train_indexes]\n            y_test = y.iloc[x_test_indexes]\n            y_val = y.iloc[x_val_indexes]\n\n            binary_classifier = RandomForestClassifier(\n            class_weight='balanced',\n            max_depth=depth,\n            n_estimators=n_trees\n            )\n\n            multiclass_classifier = RandomForestClassifier(\n            class_weight='balanced',\n            max_depth=7,\n            n_estimators=100\n            )\n\n            y_train_binary = (y_train == \"*Control\").map({True: \"*Control\", False: \"Bacteria\"})\n            y_test_binary = (y_test == \"*Control\").map({True: \"*Control\", False: \"Bacteria\"})\n            y_val_binary = (y_val == \"*Control\").map({True: \"*Control\", False: \"Bacteria\"})\n            X_test_multi = X_test.query('group != \"*Control\"')\n            X_train_multi = X_train.query('group != \"*Control\"')\n            X_val_multi = X_val.query('group != \"*Control\"')\n            y_test_multi = y_test.loc[lambda x: x != \"*Control\"]\n            y_train_multi = y_train.loc[lambda x: x != \"*Control\"]\n            y_val_multi = y_val.loc[lambda x: x != \"*Control\"]\n            binary_classifier.fit(X_train, y_train_binary)\n            multiclass_classifier.fit(X_train_multi, y_train_multi)\n            binary_val_preds = binary_classifier.predict(X_val)\n            binary_pred_xval = X_val.assign(y_pred=binary_val_preds)\n            multi_xval = binary_pred_xval.query('y_pred != \"*Control\"').drop(columns='y_pred')\n            multi_preds = multiclass_classifier.predict(multi_xval)\n            multi_pred_xval = multi_xval.assign(y_pred=multi_preds)\n            val_true_pred_df = (pd.concat([binary_pred_xval.query('y_pred == \"*Control\"'),\n                    multi_pred_xval])\n            .reset_index()\n            .rename(columns={'group': 'y_true'})\n            [['particle_index', 'y_true', 'y_pred']]\n            .assign(correct=lambda dd: dd.y_true == dd.y_pred)\n            )\n            binary_acc = (binary_pred_xval.reset_index().rename(columns={'group': 'y_true'})\n            [['particle_index', 'y_true', 'y_pred']]\n            .assign(y_true=lambda dd: np.where(dd.y_true == \"*Control\", \"*Control\", \"Bacteria\"))\n            .assign(correct=lambda dd: dd.y_true == dd.y_pred)\n            .groupby('y_true')\n            .correct.mean().mean()\n            )\n\n            multi_acc = (val_true_pred_df\n            .groupby('y_true')\n            .correct.mean()\n            .mean()\n            )\n\n            test_preds_binary = binary_classifier.predict(X_test)\n            train_preds_binary = binary_classifier.predict(X_train)\n            val_preds_binary = binary_classifier.predict(X_val)\n            train_cm_binary = (pd.crosstab(y_train_binary, train_preds_binary)\n            .reset_index()\n            .melt('group')\n            .rename(columns={'group': 'y_true', 'col_0': 'y_pred', 'value': 'n'})\n            .groupby('y_true')\n            [['y_true', 'y_pred', 'n']]\n            .apply(lambda dd: dd.assign(freq=dd.n / dd.n.sum()), include_groups=True)\n            .reset_index(drop=True)\n                    )\n            test_cm_binary = (pd.crosstab(y_test_binary, test_preds_binary)\n            .reset_index()\n            .melt('group')\n            .rename(columns={'group': 'y_true', 'col_0': 'y_pred', 'value': 'n'})\n            .groupby('y_true')\n            [['y_true', 'y_pred', 'n']]\n            .apply(lambda dd: dd.assign(freq=dd.n / dd.n.sum()), include_groups=True)\n            .reset_index(drop=True)\n            )\n            \n            train_preds_multi = multiclass_classifier.predict(X_train_multi)\n            test_preds_multi = multiclass_classifier.predict(X_test_multi)\n            val_preds_multi = multiclass_classifier.predict(X_val_multi)\n\n            train_cm_multi = (pd.crosstab(y_train_multi, train_preds_multi)\n                .reset_index()\n                .melt('group')\n                .rename(columns={'group': 'y_true', 'col_0': 'y_pred', 'value': 'n'})\n                .groupby('y_true')\n                [['y_true', 'y_pred', 'n']]\n                .apply(lambda dd: dd.assign(freq=dd.n / dd.n.sum()), include_groups=True)\n                .reset_index(drop=True)\n                    )\n            test_cm_multi = (pd.crosstab(y_test_multi, test_preds_multi)\n                .reset_index()\n                .melt('group')\n                .rename(columns={'group': 'y_true', 'col_0': 'y_pred', 'value': 'n'})\n                .groupby('y_true')\n                [['y_true', 'y_pred', 'n']]\n                .apply(lambda dd: dd.assign(freq=dd.n / dd.n.sum()), include_groups=True)\n                .reset_index(drop=True)\n            )\n\n            train_balanced_acc_binary = train_cm_binary.loc[lambda dd: dd.y_true==dd.y_pred].freq.mean()\n            test_balanced_acc_binary = test_cm_binary.loc[lambda dd: dd.y_true==dd.y_pred].freq.mean()\n            train_balanced_acc_multi = train_cm_multi.loc[lambda dd: dd.y_true==dd.y_pred].freq.mean()\n            test_balanced_acc_multi = test_cm_multi.loc[lambda dd: dd.y_true==dd.y_pred].freq.mean()\n\n            model_results['matrix'].append(name)\n            model_results['depth'].append(depth)\n            model_results['n_trees'].append(n_trees)\n            model_results['train_binary_accuracy'].append(train_balanced_acc_binary.round(4))\n            model_results['train_multiclass_accuracy'].append(train_balanced_acc_multi.round(4))\n            model_results['test_binary_accuracy'].append(test_balanced_acc_binary.round(4))\n            model_results['test_multiclass_accuracy'].append(test_balanced_acc_multi.round(4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSupplementary Figure 7: summary of the hyperparameter search\n\nf = (pd.DataFrame(model_results)\n .melt(['matrix', 'depth', 'n_trees'])\n .query('variable.str.contains(\"test\")')\n .assign(matrix=lambda dd: dd['matrix']\n         .str.replace('Lifetimes', 'LT', regex=False)\n         .str.replace('Scatter Images', 'SI', regex=False)\n         .str.replace('Fluorescence spectra', 'FS', regex=False)\n         .str.replace('_only', '', regex=False)\n         )\n .assign(variable=lambda dd: dd.variable.str.replace('test_', '')\n         .str.replace('binary_', 'Binary ', regex=False)\n         .str.replace('multiclass_', 'Multiclass ', regex=False))\n .pipe(lambda dd: p9.ggplot(dd) + p9.aes('factor(depth)', 'factor(n_trees)', fill='value')\n        + p9.geom_tile()\n        + p9.facet_wrap('matrix + \" \" + variable', ncol=4)\n        + p9.scale_x_discrete(expand=(0, 0))\n        + p9.scale_y_discrete(expand=(0, 0))\n        + p9.geom_text(p9.aes(label='round(value, 2)', color='(value - .5).abs() &lt; .35'), size=6)\n        + p9.scale_color_manual(['white', 'black'])\n        + p9.scale_fill_cmap('RdYlGn')\n        + p9.guides(fill=False, color=False)\n        + p9.labs(x='Depth of decision trees', y='Number of estimator trees')\n        + p9.theme(figure_size=(8, 7),\n                   axis_text_y=p9.element_text(size=7),\n                   )\n       )\n)\nf.save('../output/figures/combi_ms/supp_figure_7_hyperparam.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\nnaive_df = pd.DataFrame(dict(matrix=['Naïve Model', 'Naïve Model'],\n                  model_class=['Binary Classifier', 'Multiclass Classifier'],\n                  value=[.5, .2],\n)\n)\n\n\nmodels_best_table = (pd.concat([pd.DataFrame(model_results)\n .melt(['matrix', 'depth', 'n_trees'])\n .query('variable.str.contains(\"test\")')\n .assign(model_class=lambda dd: dd.variable.str.split('_').str[1].str.capitalize() + \" Classifier\")\n .drop(columns='variable')\n .groupby(['matrix', 'model_class'], as_index=False)\n .apply(lambda dd: dd.sort_values('value', ascending=False).head(1)),\nnaive_df])\n  .assign(matrix=lambda dd: dd['matrix']\n         .str.replace('Lifetimes', 'LT', regex=False)\n         .str.replace('Scatter Images', 'SI', regex=False)\n         .str.replace('Fluorescence spectra', 'FS', regex=False)\n         .str.replace('only', '', regex=False)\n         )\n .assign(label=lambda dd: (dd['value'] * 100).astype(str).str[:5] + \"%\")\n)\n\nmodels_best_table\n\n\n\n\n\n\n\n\nmatrix\ndepth\nn_trees\nvalue\nmodel_class\nlabel\n\n\n\n\n(0, 1363)\nFS + LT\n5.0\n125.0\n0.9674\nBinary Classifier\n96.74%\n\n\n(1, 2029)\nFS + LT\n11.0\n275.0\n0.6924\nMulticlass Classifier\n69.24%\n\n\n(2, 1278)\nFS + LT + SI\n5.0\n250.0\n0.9581\nBinary Classifier\n95.81%\n\n\n(3, 1926)\nFS + LT + SI\n9.0\n200.0\n0.6557\nMulticlass Classifier\n65.57%\n\n\n(4, 1445)\nFS + SI\n3.0\n175.0\n0.8050\nBinary Classifier\n80.5%\n\n\n(5, 2114)\nFS + SI\n11.0\n150.0\n0.5110\nMulticlass Classifier\n51.1%\n\n\n(6, 1634)\nFS\n5.0\n150.0\n0.7956\nBinary Classifier\n79.56%\n\n\n(7, 2257)\nFS\n3.0\n225.0\n0.4713\nMulticlass Classifier\n47.13%\n\n\n(8, 1542)\nLT + SI\n5.0\n100.0\n0.9536\nBinary Classifier\n95.36%\n\n\n(9, 2242)\nLT + SI\n19.0\n100.0\n0.6525\nMulticlass Classifier\n65.25%\n\n\n(10, 1721)\nLT\n5.0\n75.0\n0.9670\nBinary Classifier\n96.7%\n\n\n(11, 2388)\nLT\n11.0\n250.0\n0.6927\nMulticlass Classifier\n69.27%\n\n\n(12, 1807)\nSI\n3.0\n225.0\n0.7339\nBinary Classifier\n73.39%\n\n\n(13, 2463)\nSI\n9.0\n125.0\n0.4457\nMulticlass Classifier\n44.57%\n\n\n0\nNaïve Model\nNaN\nNaN\n0.5000\nBinary Classifier\n50.0%\n\n\n1\nNaïve Model\nNaN\nNaN\n0.2000\nMulticlass Classifier\n20.0%\n\n\n\n\n\n\n\n\nf = (models_best_table\n .pipe(lambda dd: p9.ggplot(dd) \n       + p9.aes('reorder(matrix, value)', 'value')\n       + p9.geom_col(p9.aes(fill='matrix != \"FS + LT\"'))\n       + p9.scale_fill_manual(['salmon', 'gray'])\n       + p9.coord_flip()\n       + p9.facet_wrap('~model_class')\n       + p9.guides(fill=False)\n       + p9.scale_y_continuous(expand=(0, 0, .12, 0), \n                               breaks=[0, .2, .4, .6, .8, 1], labels=percent_format())\n       + p9.theme(figure_size=(6, 2.5))\n       + p9.geom_text(p9.aes(label='label'), nudge_y=.125, size=8)\n       + p9.labs(y='Test set accuracy', x='')\n )\n)\nf.save('../output/figures/combi_ms/fig_9_best_model.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\nthe_best = (pd.DataFrame(model_results)\n .query('matrix==\"Fluorescence spectra + Lifetimes\"')\n .melt(['matrix', 'depth', 'n_trees'])\n .assign(model_type=lambda dd: dd.variable.str.split('_').str[1].str.capitalize() + \" Classifier\")\n .assign(set=lambda dd: dd.variable.str.split('_').str[0].str.capitalize() + \" set\")\n .assign(set=lambda dd: pd.Categorical(dd['set'], ['Train set', 'Test set']))\n .query('set==\"Test set\"')\n .groupby(['matrix', 'model_type'])\n .apply(lambda dd: dd.sort_values('value', ascending=False).head(1))\n .reset_index(drop=True)\n)\n\n\nf = (pd.DataFrame(model_results)\n .query('matrix==\"Fluorescence spectra + Lifetimes\"')\n .melt(['matrix', 'depth', 'n_trees'])\n .assign(model_type=lambda dd: dd.variable.str.split('_').str[1].str.capitalize() + \" Classifier\")\n .assign(set=lambda dd: dd.variable.str.split('_').str[0].str.capitalize() + \" set\")\n .assign(set=lambda dd: pd.Categorical(dd['set'], ['Train set', 'Test set']))\n .assign(label=lambda dd: ((dd['value'] * 100).round(1).astype(str).str[:4] + \"%\").str.replace('100.', '100', regex=False))\n .sort_values('depth')\n .pipe(lambda dd: p9.ggplot(dd)\n      + p9.aes('factor(depth)', 'factor(n_trees)')\n       + p9.geom_tile(p9.aes(fill='value'), color='black')\n       + p9.facet_grid('model_type ~ set')\n       + p9.geom_text(p9.aes(label='label', color='value &gt; .9'), size=5.5)\n       + p9.scale_fill_cmap('viridis')\n       + p9.scale_y_discrete(expand=(0, 0))\n        + p9.guides(fill=False, color=False)\n       + p9.scale_color_manual(['white', 'black'])\n       + p9.labs(x='Depth of decision trees', y='Number of estimator trees')\n       + p9.theme(figure_size=(6, 5)),\n )\n)\nf.save('../output/figures/combi_ms/fig_10_hyperparams_best_models.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\n\n\nPrecision-Recall and confusion matrices\n\nbinary_classifier = RandomForestClassifier(\n    class_weight='balanced',\n    max_depth=5,\n    n_estimators=125\n)\n\nmulticlass_classifier = RandomForestClassifier(\n    class_weight='balanced',\n    max_depth=11,\n    n_estimators=275\n)\n\n\nmatrix = matrices[1].copy()\ny = matrix.reset_index().group\nX_train = matrix.iloc[x_train_indexes]\nX_val = matrix.iloc[x_val_indexes]\ny_train = y.iloc[x_train_indexes]\ny_val = y.iloc[x_val_indexes]\ny_train_binary = (y_train == \"*Control\").map({True: \"*Control\", False: \"Bacteria\"})\ny_val_binary = (y_val == \"*Control\").map({True: \"*Control\", False: \"Bacteria\"})\nX_test_multi = X_test.query('group != \"*Control\"')\nX_train_multi = X_train.query('group != \"*Control\"')\nX_val_multi = X_val.query('group != \"*Control\"')\ny_train_multi = y_train.loc[lambda x: x != \"*Control\"]\ny_val_multi = y_val.loc[lambda x: x != \"*Control\"]\n\n\nbinary_classifier.fit(X_train, y_train_binary)\nmulticlass_classifier.fit(X_train_multi, y_train_multi)\n\nRandomForestClassifier(class_weight='balanced', max_depth=11, n_estimators=275)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifier?Documentation for RandomForestClassifieriFittedRandomForestClassifier(class_weight='balanced', max_depth=11, n_estimators=275) \n\n\n\nbinary_val_preds = binary_classifier.predict(X_val)\nbinary_pred_xval = X_val.assign(y_pred=binary_val_preds)\nmulti_xval = binary_pred_xval.query('y_pred != \"*Control\"').drop(columns='y_pred')\nmulti_preds = multiclass_classifier.predict(multi_xval)\nmulti_pred_xval = multi_xval.assign(y_pred=multi_preds).reset_index().rename(columns={'group': 'y_true'})[['particle_index', 'y_true', 'y_pred']]\n\n\nval_true_pred_df = (pd.concat([binary_pred_xval\n            .query('y_pred == \"*Control\"')\n            .reset_index()\n            .rename(columns={'group': 'y_true'})\n            [['particle_index', 'y_true', 'y_pred']],\n           multi_pred_xval])\n  .reset_index()\n  [['particle_index', 'y_true', 'y_pred']]\n .assign(correct=lambda dd: dd.y_true == dd.y_pred)\n)\n\n\nval_cm = (pd.crosstab(val_true_pred_df.y_true, val_true_pred_df.y_pred)\n .reset_index()\n .melt('y_true')\n .rename(columns={'value': 'n'})\n .groupby('y_true').apply(lambda dd: dd.assign(freq=dd.n / dd.n.sum())).reset_index(drop=True)\n )\n\nf = (val_cm\n .assign(group='Validation set')\n .pipe(lambda dd: p9.ggplot(dd) \n     + p9.aes('y_pred', 'y_true', fill='freq')\n       + p9.geom_tile(p9.aes(width=.985, height=.975), color='white')\n       + p9.theme(figure_size=(4.5, 4.5), axis_text_x=p9.element_text(rotation=90))\n       + p9.geom_text(p9.aes(label='n', color='freq &gt; .5'))\n       + p9.scale_x_discrete(expand=(0, 0))\n       + p9.scale_y_discrete(expand=(0, 0))\n       + p9.scale_fill_continuous('inferno')\n       + p9.scale_color_manual(['white', 'black'])\n       + p9.labs(x='$Y_{pred}$', y='$Y_{true}$', title='Performance on validation set')\n       + p9.guides(fill=False, color=False)\n )\n)\nf.save('../output/figures/validation_confusion_matrix.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\nrecalls = (pd.crosstab(val_true_pred_df.y_true, val_true_pred_df.y_pred,\n                             normalize='index')\n    .reset_index()\n    .melt('y_true')\n    .query('y_true == y_pred')\n    .assign(variable='Recall (TP / TP + FN)')\n)\n\nprecisions = (pd.crosstab(val_true_pred_df.y_true, val_true_pred_df.y_pred,\n                            normalize='columns')\n    .reset_index()\n    .melt('y_true')\n    .query('y_true == y_pred')\n    .assign(variable='Precision (TP / TP + FP)')\n)\n\n\nprecision_and_recall = pd.concat([recalls, precisions])\nf = (precision_and_recall\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes('y_true', 'value', fill='value')\n       + p9.geom_col()\n       + p9.scale_fill_cmap('Oranges', limits=(None, 1))\n       + p9.facet_wrap('variable')\n       + p9.coord_flip()\n       + p9.geom_text(p9.aes(label='(round(value, 3) * 100).astype(str).str[:4] + \"%\"', color='value &lt; .9'), \n                      y=.175, size=8)\n       + p9.scale_color_manual(['white', 'black'])\n       + p9.scale_y_continuous(expand=(0, 0, .15, 0), labels=percent_format())\n       + p9.guides(fill=False, color=False)\n       + p9.labs(x='', y='')\n       + p9.theme(figure_size=(4, 3))\n ))\nf.save('../output/figures/validation_precision_recall.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\nbinary_pred_true_false = (binary_pred_xval\n                          .reset_index()\n                          .assign(y_true=lambda dd: \n                                  np.where(dd.group==\"*Control\", \"*Control\", \"Bacteria\"))\n                          [['y_true', 'y_pred', 'particle_index']]\n)\n\nrecalls = (pd.crosstab(binary_pred_true_false['y_true'], binary_pred_true_false.y_pred,\n                             normalize='index')\n    .reset_index()\n    .melt('y_true')\n    .query('y_true == y_pred')\n    .assign(variable='Recall (TP / TP + FN)')\n)\n\nprecisions = (pd.crosstab(binary_pred_true_false['y_true'], binary_pred_true_false.y_pred,\n                                normalize='columns')\n        .reset_index()\n        .melt('y_true')\n        .query('y_true == y_pred')\n        .assign(variable='Precision (TP / TP + FP)')\n    )\n\n\nprecision_and_recall = pd.concat([recalls, precisions])\nf = (precision_and_recall\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes('y_true', 'value', fill='value')\n       + p9.geom_col()\n       + p9.scale_fill_cmap('Oranges', limits=(.5, 1))\n       + p9.facet_wrap('variable')\n       + p9.coord_flip()\n       + p9.geom_text(p9.aes(label='(round(value, 3) * 100).astype(str).str[:4] + \"%\"'),\n                      y=.15, size=8, color='white')\n       + p9.scale_y_continuous(expand=(0, 0, .15, 0), labels=percent_format())\n       + p9.guides(fill=False)\n       + p9.labs(x='', y='')\n       + p9.theme(figure_size=(4, 2))\n ))\nf.save('../output/figures/binary_precision_recall.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\nClass-specific Recall and Precision\n\n(recall_precision\n .melt('group')\n .replace({'recall': 'Recall (TP / TP + FN)',\n           'precision': 'Precision (TP / TP + FP)'})\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes('group', 'value', fill='value')\n       + p9.geom_col()\n       + p9.scale_fill_continuous('Oranges')\n       + p9.coord_flip()\n       + p9.geom_text(p9.aes(label='(round(value, 3) * 100).astype(str).str[:4] + \"%\"'),\n                      y=.15, size=8)\n       + p9.facet_wrap('variable')\n       + p9.guides(fill=False)\n       + p9.labs(x='', y='')\n       + p9.theme(figure_size=(5, 3)))\n)\n\n\n\n\n\n\n\n\n\n\nFeature Importances"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "",
    "section": "1.1 Overview",
    "text": "1.1 Overview\nThis repository contains the code and data to reproduce the results of the manuscript “Benchmarking Laser-induced Fluorescence and Machine Learning for real-time identification of bacteria in bioaerosols” by Fontal et al. (2025). In this study, we demonstrate a method to (1) aerosolize bacteria using a nebulizer emulating bacteria-laden droplets, (2) modify an existing equipment (Rapid-E) to facilitate the characterization of microbial aerosols and (3) use machine learning models to detect bacteria and classify them in near-real time."
  },
  {
    "objectID": "index.html#reports",
    "href": "index.html#reports",
    "title": "",
    "section": "1.2 Reports",
    "text": "1.2 Reports\nHere you will find two reports:\n\nbacteria_ms.ipynb: This notebook contains the main analysis and results of the manuscript, where we analyze the aerosolized bacteria and train and evaluate random forests to classify them.\nfluorophore_ms.ipynb: This notebook contains the tests that we ran with aerosolized fluorophores, which were used to validate the Rapid-E modifications and its ability to detect the fluorophores characteristic of bacterial cells as part of aerosol particles."
  },
  {
    "objectID": "fluorophores_ms.html",
    "href": "fluorophores_ms.html",
    "title": "Detecting aerosolized fluorophores with Rapid-E",
    "section": "",
    "text": "import os\nimport sys\nimport bz2\nimport pickle\n\n\nsys.path.append('..')\nsys.path.append('../../aerosolpy')\n\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotnine as p9\nimport matplotlib.pyplot as plt\n\nfrom glob import glob\nfrom tqdm.auto import tqdm\nfrom functools import partial\nfrom collections import defaultdict\nfrom mizani.breaks import date_breaks\nfrom mizani.formatters import date_format, percent_format\nfrom scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\n\nfrom aerosolpy.conversion import Conversion\nfrom aerosolpy.particles import AerosolParticlesData, ParticleData\nfrom aerosolpy.particles import (CORRECTED_SPECTRAL_WAVELENGTHS,\n                                 WAVELENGTH_LIFETIME_RANGES,\n                                 SCATTERING_ANGLES)\n\n\n\n\n\n# Matplotlib settings\nfrom matplotlib_inline.backend_inline import set_matplotlib_formats\nplt.rcParams['font.family'] = 'Georgia'\nplt.rcParams['svg.fonttype'] = 'none'\nset_matplotlib_formats('retina')\nplt.rcParams['figure.dpi'] = 300\n# Plotnine settings (for figures)\n\np9.options.set_option('base_family', 'Georgia')\n\np9.theme_set(\n    p9.theme_bw()\n    + p9.theme(panel_grid=p9.element_blank(),\n               legend_background=p9.element_blank(),\n               panel_grid_major=p9.element_line(size=.5, linetype='dashed',\n                                                alpha=.15, color='black'),\n               dpi=300\n    )\n)"
  },
  {
    "objectID": "fluorophores_ms.html#preamble",
    "href": "fluorophores_ms.html#preamble",
    "title": "Detecting aerosolized fluorophores with Rapid-E",
    "section": "",
    "text": "import os\nimport sys\nimport bz2\nimport pickle\n\n\nsys.path.append('..')\nsys.path.append('../../aerosolpy')\n\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotnine as p9\nimport matplotlib.pyplot as plt\n\nfrom glob import glob\nfrom tqdm.auto import tqdm\nfrom functools import partial\nfrom collections import defaultdict\nfrom mizani.breaks import date_breaks\nfrom mizani.formatters import date_format, percent_format\nfrom scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\n\nfrom aerosolpy.conversion import Conversion\nfrom aerosolpy.particles import AerosolParticlesData, ParticleData\nfrom aerosolpy.particles import (CORRECTED_SPECTRAL_WAVELENGTHS,\n                                 WAVELENGTH_LIFETIME_RANGES,\n                                 SCATTERING_ANGLES)\n\n\n\n\n\n# Matplotlib settings\nfrom matplotlib_inline.backend_inline import set_matplotlib_formats\nplt.rcParams['font.family'] = 'Georgia'\nplt.rcParams['svg.fonttype'] = 'none'\nset_matplotlib_formats('retina')\nplt.rcParams['figure.dpi'] = 300\n# Plotnine settings (for figures)\n\np9.options.set_option('base_family', 'Georgia')\n\np9.theme_set(\n    p9.theme_bw()\n    + p9.theme(panel_grid=p9.element_blank(),\n               legend_background=p9.element_blank(),\n               panel_grid_major=p9.element_line(size=.5, linetype='dashed',\n                                                alpha=.15, color='black'),\n               dpi=300\n    )\n)"
  },
  {
    "objectID": "fluorophores_ms.html#loading-data",
    "href": "fluorophores_ms.html#loading-data",
    "title": "Detecting aerosolized fluorophores with Rapid-E",
    "section": "Loading Data",
    "text": "Loading Data\n\nfor folder in glob('../data/fluorophores/*'):\n    fluorophore = os.path.basename(folder)\n    if os.path.exists(f'{folder}/particles.pickle.bz2'):\n        continue\n    else: \n        for filename in glob(f'{folder}/*.zip'):\n            converter = Conversion(filename, mode='user', keep_threshold=True, keep_zip=True)\n            converter.save_overall()\n        particles = AerosolParticlesData.from_folder(folder)\n        with bz2.BZ2File(f'{folder}/particles.pickle.bz2', 'w') as fh:\n            pickle.dump(particles, fh)\n\n\nparticles_dict = {}\nfor folder in glob('../data/fluorophores/*'):\n    fluorophore = os.path.basename(folder)\n    with bz2.BZ2File(f'{folder}/particles.pickle.bz2', 'r') as fh:\n        particles = pickle.load(fh)\n    particles_dict[fluorophore] = particles\n\n\nsummary_df = []\nfor fluorophore, particles in particles_dict.items():\n    summary_df.append(particles.summary_df.assign(fluorophore=fluorophore))\nsummary_df = pd.concat(summary_df)\n\n\n(summary_df\n .replace({'fluorophore': {'Riboflavin+acetic': 'Riboflavin\\n[AcOH]'}})\n .assign(fluorescent=lambda dd: dd['intensity'] &gt;= 2000)\n .groupby(['fluorophore'])\n .size()\n .rename('count')\n .sort_values(ascending=False)\n .apply(lambda x: int(round(x / 10)))\n)\n\nfluorophore\nTyrosine              4064\nRiboflavin\\n[AcOH]    3132\nTryptophan            2162\nNADH                  1885\nRiboflavin             853\nName: count, dtype: int64\n\n\n\nf = (summary_df\n .replace({'fluorophore': {'Riboflavin+acetic': 'Riboflavin\\n[AcOH]'}})\n .assign(fluorescent=lambda dd: dd['intensity'] &gt;= 2000)\n .groupby(['fluorophore', 'fluorescent'])\n .size()\n .rename('count')\n .reset_index()\n .assign(percentages=lambda dd: dd.groupby('fluorophore')['count'].transform(lambda x: x / x.sum() * 100).round(2))\n .assign(fluorophore=lambda dd: pd.Categorical(dd['fluorophore'], categories=dd.query('fluorescent').sort_values('percentages')['fluorophore']))\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes(x='fluorophore', y='count', fill='fluorescent')\n       + p9.geom_col()\n       + p9.coord_flip()\n       + p9.geom_text(p9.aes(label='percentages.astype(str) + \"%\"'),\n                      nudge_y=1000, size=8, ha='left',\n                       data=dd.query('fluorescent'))\n       + p9.scale_y_continuous(expand=(0, 0, .1, 0))\n       + p9.scale_fill_manual(values=[None, '#00FF00'])\n       + p9.labs(x='', y='Total number of aerosol particles', fill='Fluorescent*',\n                 caption='*Max Fluorescence Intensity &gt;= 2000 [a.u.]')\n       + p9.theme(figure_size=(4, 3), legend_position='top',\n                   plot_caption=p9.element_text(size=7))\n )\n       )\n\nf.save('../output/figures/fluorophores_fluorescent_counts.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\nintensity_stats = (summary_df\n .groupby('fluorophore')\n .agg(mean=('intensity', 'mean'),\n      median=('intensity', 'median'),\n      q95=('intensity', lambda x: np.percentile(x, 95)),\n      q99=('intensity', lambda x: np.percentile(x, 99)))\n      .reset_index()\n)\nintensity_stats\n\n\n\n\n\n\n\n\nfluorophore\nmean\nmedian\nq95\nq99\n\n\n\n\n0\nNADH\n694.887509\n610.0\n1324.0\n2360.35\n\n\n1\nRiboflavin\n703.847867\n557.0\n1425.0\n3403.46\n\n\n2\nRiboflavin+acetic\n1089.236964\n634.0\n3793.4\n8261.40\n\n\n3\nTryptophan\n998.281373\n772.0\n1983.0\n5381.74\n\n\n4\nTyrosine\n676.762471\n592.0\n1284.0\n2028.30\n\n\n\n\n\n\n\n\nf = (summary_df\n .assign(intensity=lambda dd: dd.intensity.astype(int))\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.geom_histogram(p9.aes(x='intensity'), binwidth=100)\n       + p9.facet_wrap('fluorophore', ncol=1, scales='free_y')\n       + p9.geom_vline(p9.aes(xintercept='median'), color='red', linetype='dashed',\n                       data=intensity_stats)\n       + p9.geom_vline(p9.aes(xintercept='q95'), color='blue', linetype='dashed',\n                          data=intensity_stats)\n       + p9.geom_vline(p9.aes(xintercept='q99'), color='blue', linetype='dotted',\n                       data=intensity_stats)\n       + p9.labs(x='Fluorescence Intensity [a.u.]', y='Particles count')\n       + p9.scale_x_continuous(limits=(0, 10000))\n       + p9.theme(figure_size=(4, 3.5),\n                  axis_text_y=p9.element_text(size=7))\n )\n)\nf.save('../output/figures/fluorescence_intensity_histograms.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\nparticles_dict['Tyrosine'].filter('intensity &gt; 3000')\n\nFiltering particles with query: intensity &gt; 3000\n\n\nCollection of 179 aerosol particles measured from 2021-01-27 15:44:02 to 2021-01-27 15:53:58.\n\n\n\nfluo_particles_dict = {}\nfor fluorophore, particles in particles_dict.items():\n    fluo_particles_dict[fluorophore] = particles.filter('intensity &gt;= 2000')\n\nFiltering particles with query: intensity &gt;= 2000\nFiltering particles with query: intensity &gt;= 2000\nFiltering particles with query: intensity &gt;= 2000\nFiltering particles with query: intensity &gt;= 2000\nFiltering particles with query: intensity &gt;= 2000\n\n\n\nsuper_fluo_particles_dict = {}\nfor fluorophore, particles in particles_dict.items():\n    super_fluo_particles_dict[fluorophore] = particles.filter('intensity &gt;= 2500')\n\nFiltering particles with query: intensity &gt;= 2500\nFiltering particles with query: intensity &gt;= 2500\nFiltering particles with query: intensity &gt;= 2500\nFiltering particles with query: intensity &gt;= 2500\nFiltering particles with query: intensity &gt;= 2500\n\n\n\nspectra_df = []\nfor fluorophore in super_fluo_particles_dict:\n    for i, particle in enumerate(super_fluo_particles_dict[fluorophore]):\n        spectra_df.append(particle.spectrum_time_matrix.sum(axis=1)\n                  .rename('intensity')\n                  .reset_index()\n                  .assign(relative_intensity=lambda dd: dd['intensity'] / dd['intensity'].max())\n                  .assign(fluorophore=fluorophore)\n                  .assign(particle_index=i)\n                  .assign(max_intensity=lambda dd: dd['intensity'].max())\n )\nspectra_df = pd.concat(spectra_df)\n\n\nn = 100\nselected_particles = (spectra_df\n .groupby('fluorophore')\n .apply(lambda dd: dd[['particle_index', 'max_intensity']].drop_duplicates()\n        .sort_values('max_intensity', ascending=False)\n        .head(n).assign(new_index=range(n)))\n        .reset_index()\n [['fluorophore', 'particle_index', 'new_index']]\n)\n\n\nf = (spectra_df\n .merge(selected_particles, on=['fluorophore', 'particle_index'])\n .replace('Riboflavin+acetic', 'Riboflavin [AcOH]')\n .assign(fluorophore=lambda dd: pd.Categorical(dd['fluorophore'], categories= [\n     'Tyrosine', 'Tryptophan', 'NADH', 'Riboflavin', 'Riboflavin [AcOH]'\n ]))\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes(x='wavelength', y='new_index')\n         + p9.geom_tile(p9.aes(fill='relative_intensity'))\n         + p9.scale_x_continuous(expand=(0, 0), breaks=range(300, 601, 50))\n         + p9.scale_y_continuous(expand=(0, 0))\n         + p9.scale_fill_cmap('viridis', labels=percent_format())\n         + p9.facet_wrap('fluorophore')\n         + p9.labs(x='Wavelength [nm]', fill='Relative Intensity')\n         + p9.theme(axis_text_y=p9.element_blank(),\n                      axis_title_y=p9.element_blank(),\n                      axis_ticks_major_y=p9.element_blank(),\n                      legend_position=(.9, .125),\n                      legend_key_size=10,\n                      legend_text=p9.element_text(size=8),\n                      legend_title=p9.element_text(size=9, ha='center'),\n                      axis_title_x=p9.element_text(size=10, va='top'),\n                      axis_text_x=p9.element_text(size=7),\n                      figure_size=(6, 4),\n                      plot_margin=.03\n         )\n )\n)\nf.save('../output/figures/fluorophores_fluorescence_spectra.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\nf = (spectra_df\n .merge(selected_particles, on=['fluorophore', 'particle_index'])\n .replace('Riboflavin+acetic', 'Riboflavin [AcOH]')\n .assign(fluorophore=lambda dd: pd.Categorical(dd['fluorophore'], categories= [\n     'Tyrosine', 'Tryptophan', 'NADH', 'Riboflavin', 'Riboflavin [AcOH]'\n ]))\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes(x='wavelength', y='relative_intensity')\n       + p9.scale_color_manual(['black', '#EE1E26', '#5EBE46', '#344CA5', \"#344CA5\"])\n       + p9.scale_fill_manual(['black', '#EE1E26', '#5EBE46', '#344CA5', \"#344CA5\"])\n       + p9.scale_x_continuous(breaks=range(300, 601, 50))\n       + p9.scale_y_continuous(breaks=[0, .2, .4, .6, .8, 1])\n       + p9.labs(y='Relative Fluorescence Intensity [a.u.]', x='Wavelength [nm]', color='', fill='')\n       + p9.stat_summary(geom='line', size=.7, fun_y=np.median, mapping=p9.aes(color='fluorophore', linetype='fluorophore==\"Riboflavin\"'))\n       + p9.stat_summary(fun_ymax=lambda x: x.quantile(.75),\n                         fun_ymin=lambda x: x.quantile(.25),\n                          geom='ribbon', alpha=.15, mapping=p9.aes(fill='fluorophore'))\n       + p9.guides(linetype=False)\n       + p9.theme(figure_size=(5, 3),\n                  axis_title_y=p9.element_text(size=10),\n       )\n    )\n       )\nf.save('../output/figures/fluorophores_fluorescence_spectra_median.svg')\nf.draw()\n\n\n\n\n\n\n\n\n\nlifetimes = []\nfor fluorophore, particles in super_fluo_particles_dict.items():\n    selected_idxs = selected_particles.query('fluorophore == @fluorophore')['particle_index']\n    for i in selected_idxs:\n        particle = particles[i]\n        lifetimes.append(particle.lifetime\n                         .assign(fluorophore=fluorophore)\n                         .assign(particle_index=i)\n        )\nlifetimes = pd.concat(lifetimes)\n\n\nlifetime_stats = (lifetimes\n .replace({'350-400 nm': '300-340 nm'})\n .groupby(['fluorophore', 'time', 'wavelength_range'], as_index=False)\n .agg(\n     median=('intensity', 'median'),\n    q05=('intensity', lambda x: x.quantile(.05)),\n    q25=('intensity', lambda x: x.quantile(.25)),\n    q75=('intensity', lambda x: x.quantile(.75)),\n    q95=('intensity', lambda x: x.quantile(.95)),\n )\n)\n\n\n(lifetime_stats\n .replace('Riboflavin+acetic', 'Riboflavin [AcOH]')\n .pipe(lambda dd: p9.ggplot(dd)\n       + p9.aes(x='time', y='median', color='wavelength_range')\n       + p9.geom_line()\n       + p9.facet_wrap('fluorophore', ncol=3, scales='free_y')\n       + p9.labs(x='Time [ns]', y='Median Intensity [a.u.]', color='Wavelength Range')\n       + p9.theme(\n           legend_position=(.925, .1),\n           figure_size=(6, 3.5),\n           legend_title=p9.element_text(size=9),\n           legend_text=p9.element_text(size=8),\n           legend_key_size=12,\n                  )\n )\n)"
  }
]